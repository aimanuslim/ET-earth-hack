{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_name_list = glob.glob(\"Data/*.csv\")\n",
    "\n",
    "feature_set = ['wellName','DEPT', 'BS', 'CALI', 'DENS', 'DTC', 'GR', 'NEUT', 'PEF', 'RESD', 'RESM', 'RESS', 'TVD']\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for file in file_name_list:\n",
    "    df = pd.read_csv(file, index_col=None, skiprows=[1])\n",
    "    file_list.append(df[feature_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_this(y):\n",
    "    plt.plot(y)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_res(dept, pred_y, err, well, algo_name):\n",
    "    res_path = \"Results/%s\"  %well\n",
    "    if not os.path.isdir(res_path):\n",
    "        os.makedirs(res_path)\n",
    "        \n",
    "    result = pd.DataFrame({'DEPT': dept,\n",
    "                           'Pred_DTC': pred_y})\n",
    "    result.to_csv('%s/%s.csv' %(res_path, algo_name))\n",
    "    \n",
    "    score = pd.DataFrame({'ERROR' : [err]})\n",
    "    score.to_csv('%s/%s_score.csv' %(res_path, algo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "def cross_val(clf, algo_name, feature_set=['DEPT', 'BS', 'CALI', 'DENS', 'GR', 'NEUT', 'PEF', 'RESD', 'RESM', 'RESS', 'TVD']):\n",
    "    \n",
    "    wells = []\n",
    "    err_list = []\n",
    "\n",
    "    for i in range(len(file_list)):\n",
    "        test_df = file_list[i]\n",
    "        wells.append(test_df.iloc[0,0])\n",
    "        print('%s : %s' %(i, wells[i]))\n",
    "\n",
    "        train_list = file_list.copy()\n",
    "        train_list.pop(i)\n",
    "        train_df = pd.concat(train_list)\n",
    "\n",
    "        test_x = test_df[feature_set].values\n",
    "        test_y = test_df[['DTC']].values\n",
    "        test_y = test_y.ravel()\n",
    "        \n",
    "        train_X = train_df[feature_set].values\n",
    "        train_y = train_df[['DTC']].values\n",
    "        train_y = train_y.ravel()\n",
    "        \n",
    "        # feature scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit_transform(train_X)\n",
    "        scaler.transform(test_x)\n",
    "\n",
    "        # training\n",
    "        mdl = clf()\n",
    "        mdl.fit(train_X, train_y)\n",
    "\n",
    "        # testing\n",
    "        pred_y = mdl.predict(test_x)\n",
    "    \n",
    "        # error\n",
    "#         abs_error = np.divide((np.abs(np.subtract(test_y, pred_y))), test_y)\n",
    "        \n",
    "#         plt_this(abs_error)\n",
    "#         plt_this(pred_y)\n",
    "#         plt_this(test_y)\n",
    "            \n",
    "#         err = explained_variance_score(test_y, pred_y)\n",
    "        err = r2_score(test_y, pred_y)\n",
    "        \n",
    "        err_list.append(err)\n",
    "        \n",
    "        # save results\n",
    "        save_res(test_x[:,0], pred_y, err, wells[i], algo_name)\n",
    "\n",
    "    print()\n",
    "\n",
    "    avg_err = np.mean(err_list)\n",
    "\n",
    "    for i in range(len(wells)):\n",
    "        print('Test score on %s : %s' %(wells[i], err_list[i]))\n",
    "\n",
    "    print()\n",
    "    print('Average algorithm score: %s' %avg_err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Cheal-A12\n",
      "1 : Cheal-G3\n",
      "2 : Cheal-B8\n",
      "3 : Cheal-G2\n",
      "4 : Cheal-A10\n",
      "5 : Cheal-C3\n",
      "6 : Cheal-G1\n",
      "7 : Cheal-A11\n",
      "8 : Cheal-C4\n",
      "\n",
      "Test score on Cheal-A12 : 0.7929567095598402\n",
      "Test score on Cheal-G3 : 0.4857517750978849\n",
      "Test score on Cheal-B8 : 0.8162805159733997\n",
      "Test score on Cheal-G2 : 0.7466208463146158\n",
      "Test score on Cheal-A10 : 0.6955932750522589\n",
      "Test score on Cheal-C3 : 0.5887520220557325\n",
      "Test score on Cheal-G1 : 0.7541170814086443\n",
      "Test score on Cheal-A11 : -2.8890320774886575\n",
      "Test score on Cheal-C4 : 0.7564174102398002\n",
      "\n",
      "Average algorithm score: 0.3052730620237243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "feature_set = ['DEPT', 'BS', 'CALI', 'DENS', 'RESD', 'RESM'] #0.372\n",
    "\n",
    "cross_val(LinearRegression, 'Linear regression', feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Cheal-A12\n",
      "1 : Cheal-G3\n",
      "2 : Cheal-B8\n",
      "3 : Cheal-G2\n",
      "4 : Cheal-A10\n",
      "5 : Cheal-C3\n",
      "6 : Cheal-G1\n",
      "7 : Cheal-A11\n",
      "8 : Cheal-C4\n",
      "\n",
      "Test score on Cheal-A12 : 0.8309746816834526\n",
      "Test score on Cheal-G3 : 0.8206461611460605\n",
      "Test score on Cheal-B8 : 0.8935058403485543\n",
      "Test score on Cheal-G2 : 0.8147488055680218\n",
      "Test score on Cheal-A10 : 0.712277353310443\n",
      "Test score on Cheal-C3 : 0.6983074463666206\n",
      "Test score on Cheal-G1 : 0.7068053209711908\n",
      "Test score on Cheal-A11 : 0.8552643332642788\n",
      "Test score on Cheal-C4 : 0.7971721856838716\n",
      "\n",
      "Average algorithm score: 0.7921891253713882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cross_val(RandomForestRegressor, 'Random forrest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Cheal-A12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ali/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Cheal-G3\n",
      "2 : Cheal-B8\n",
      "3 : Cheal-G2\n",
      "4 : Cheal-A10\n",
      "5 : Cheal-C3\n",
      "6 : Cheal-G1\n",
      "7 : Cheal-A11\n",
      "8 : Cheal-C4\n",
      "\n",
      "Test score on Cheal-A12 : 0.8676899930722775\n",
      "Test score on Cheal-G3 : 0.899004907544544\n",
      "Test score on Cheal-B8 : 0.9109146288277108\n",
      "Test score on Cheal-G2 : 0.8711370473371597\n",
      "Test score on Cheal-A10 : 0.817540613529717\n",
      "Test score on Cheal-C3 : 0.8005543093009729\n",
      "Test score on Cheal-G1 : 0.7885271499752097\n",
      "Test score on Cheal-A11 : 0.8975993272516607\n",
      "Test score on Cheal-C4 : 0.8324517721115686\n",
      "\n",
      "Average algorithm score: 0.8539355276612022\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "cross_val(LGBMRegressor, 'Gradient boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Cheal-A12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "cross_val(SVR, 'Support vector machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN (2 layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
